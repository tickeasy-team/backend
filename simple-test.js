/**
 * ç°¡åŒ–ç‰ˆè¨­ç½®é©—è­‰
 */

import dotenv from 'dotenv';

// è¼‰å…¥ç’°å¢ƒè®Šæ•¸
dotenv.config();

console.log('ğŸš€ é–‹å§‹è¨­ç½®é©—è­‰...\n');

// 1. æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
console.log('ğŸ” æª¢æŸ¥ç’°å¢ƒè®Šæ•¸...');
const requiredVars = [
  'SUPABASE_ACCESS_TOKEN',
  'SUPABASE_PROJECT_REF', 
  'OPENAI_API_KEY',
  'DB_HOST'
];

let envCheck = true;
for (const varName of requiredVars) {
  const value = process.env[varName];
  if (!value || value.includes('your_') || value.includes('here')) {
    console.log(`âŒ ${varName}: æœªè¨­ç½®æˆ–ä½¿ç”¨é è¨­å€¼`);
    envCheck = false;
  } else {
    console.log(`âœ… ${varName}: å·²è¨­ç½®`);
  }
}

// 2. æª¢æŸ¥ OpenAI
console.log('\nğŸ” æª¢æŸ¥ OpenAI é€£æ¥...');
try {
  const { default: OpenAI } = await import('openai');
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });

  const response = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: 'æ¸¬è©¦' }],
    max_tokens: 5
  });

  console.log('âœ… OpenAI é€£æ¥æˆåŠŸ');
  console.log(`ğŸ¤– å›æ‡‰: ${response.choices[0].message.content}`);
} catch (error) {
  console.log(`âŒ OpenAI é€£æ¥å¤±æ•—: ${error.message}`);
}

console.log('\nğŸ“‹ é©—è­‰å®Œæˆ!');

if (envCheck) {
  console.log('ğŸ‰ ç’°å¢ƒè¨­ç½®æ­£ç¢ºï¼Œå¯ä»¥é€²è¡Œä¸‹ä¸€æ­¥ï¼');
} else {
  console.log('âš ï¸ è«‹è¨­ç½®ç¼ºå°‘çš„ç’°å¢ƒè®Šæ•¸');
}